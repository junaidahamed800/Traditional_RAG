{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6ae14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Document Structure\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1e75d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Junaid Ahamed', 'creation-date': '2025-11-23'}, page_content='This is the data that is converted from pdf format to document structure')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content = \"This is the data that is converted from pdf format to document structure\",\n",
    "    metadata = {\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\":\"Junaid Ahamed\",\n",
    "        \"creation-date\":\"2025-11-23\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba23b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating a txt file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\",exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a007b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, \"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41af5d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### Text Loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "print(document)\n",
    "\n",
    "### this returns the o/p in a document - data structure format which has 2 core components metadata(Dictionary) and page_content(String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9165e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.'),\n",
       " Document(metadata={'source': '../data/text_files/machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    ')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "## load all the text files from the directory\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", ## Pattern to match files  \n",
    "    loader_cls= TextLoader, ##loader class to use\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "documents=dir_loader.load()\n",
    "documents\n",
    "\n",
    "### returns a list of documents present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db39dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250821131122', 'source': '../data/pdf_files/Driving Licenese Car and bike.pdf', 'file_path': '../data/pdf_files/Driving Licenese Car and bike.pdf', 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20250821131122', 'page': 0}, page_content=\"5-2-39-A,\\nPARUVETI ARUGU STREET,\\nKOVUR,SRIPOTTISRIRAMULUNELLORE,524137\\nANDHRA PRADESH\\nIssued by\\nIndian Union Driving Licence\\n:\\n:\\n:\\n:\\n:\\nAddress:\\nHolder's Signature\\n15-07-2021\\n Issue Date\\n Validity  ( TR )\\n21-04-2043\\n Validity ( NT )\\nNo\\nOrgan Donor\\nSon/Daughter/Wife of\\nO+\\n15-07-2021\\nDate Of First Issue\\nName\\nBlood Group\\nDate Of Birth\\nSHAIK  JUNAID AHAMED\\nRASOOL AHAMED\\n22-04-2003\\nAP02620210034919\\nAP\"),\n",
       " Document(metadata={'producer': 'PDFium', 'creator': 'PDFium', 'creationdate': 'D:20250821131122', 'source': '../data/pdf_files/Driving Licenese Car and bike.pdf', 'file_path': '../data/pdf_files/Driving Licenese Car and bike.pdf', 'total_pages': 2, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': 'D:20250821131122', 'page': 1}, page_content='Form 7 Rule 16(2)\\nRTA NELLORE\\nLicencing Authority\\n6302308709\\nEmergency Contact Number\\nHill Validity\\nHazardous validity\\nNT\\nNT\\nBadge\\n Issued By\\nBadge\\nissued date\\nBadge\\nNumber\\nVehicle\\nCategory\\nADPVEH No.(Regn.Numbers)\\nDL No:\\nDate of\\nIssue\\nAP026\\nAP026\\n23-12-2023\\n13-07-2021\\nAP02620210034919\\nClass of\\nVehicle\\nCode\\nIssued by\\nMCWG\\nLMV\\n91-'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-11-13T03:37:15+00:00', 'source': '../data/pdf_files/Functions_in_Python.pdf', 'file_path': '../data/pdf_files/Functions_in_Python.pdf', 'total_pages': 2, 'format': 'PDF 1.5', 'title': \"John Doe's CV\", 'author': 'John Doe', 'subject': '', 'keywords': '', 'moddate': '2025-11-13T03:37:16+00:00', 'trapped': '', 'modDate': 'D:20251113033716Z', 'creationDate': \"D:20251113033715+00'00'\", 'page': 0}, page_content='Shaik Junaid Ahamed \\n \\njunaidahamed800@gmail.com | 7386362301 | LinkedIn | Hyderabad \\nSummary \\nDedicated and motivated Generative AI Developer with 1 year of experience in developing and integrating Large \\nLanguage Models (LLMs) along with RAG Architecture into real-world business applications using Python. Proven \\nexpertise in building scalable and intelligent AI solutions tailored to client requirements, with hands-on experience \\nin cutting-edge tools and frameworks such as LangChain, LangGraph and integrating OpenAI models. Adept at \\ndesigning robust pipelines, exploring agent-based workflows. Strong problem-solving mindset with a focus on \\ndelivering impactful, production-grade AI systems that align with business goals. \\nTechnical Skills \\nLanguages: Python, SQL, Java. \\nGenAI and Prompt Engineering: Large Language Models (LLM), RAG (Retrieval Augmented Architecture), \\nLangChain, Prompt Engineering, Knowledge on Transformers Architecture. \\nFrameworks and Libraries: FastAPI, Pydantic framework. \\nOthers: RESTful API. \\nDatabase: MYSQL. \\nSoftware\\'s and Platforms: Visual Studio Code (VS Code), Postman, GitHub, SQL Workbench. \\nProfessional Experience \\nProlifics, Inc., Software Engineer \\nMar 2025 – Present \\n• Reduced time to render user buddy lists by 75% by implementing a prediction algorithm \\n• Integrated iChat with Spotlight Search by creating a tool to extract metadata from saved chat transcripts and \\nprovide metadata to a system-wide search database \\n• Redesigned chat file format and implemented backward compatibility for search \\nHan Digital Solutions, Process Associate - AI/ML Data Operations \\nDec 2024 – Mar 2025 \\n• Worked on AI/ML data solutions by labeling and annotating datasets used for supervised learning to train LLMs \\neffectively. This process ensured the models received accurate, meaningful input for better learning and \\nperformance. \\n• Worked on different types of raw data including text, images, audio, and video into supervised datasets, and \\nLabelled data for machine learning models to understand patterns & mappings, understand context and make \\naccurate predictions. \\nPOC Experience \\nMulti-User Drawing Tool \\n \\n• Developed an electronic classroom where multiple users can simultaneously view and draw on a \"chalkboard\" \\nwith each person’s edits synchronized \\n• Tools Used: C++, MFC \\nSynchronized Desktop Calendar \\n \\n• Developed a desktop calendar with globally shared and synchronized calendars, allowing users to schedule \\nmeetings with other users \\n• Tools Used: C#, .NET, SQL, XML \\nCustom Operating System \\n \\n• Built a UNIX-style OS with a scheduler, file system, text editor, and calculator'),\n",
       " Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2025-11-13T03:37:15+00:00', 'source': '../data/pdf_files/Functions_in_Python.pdf', 'file_path': '../data/pdf_files/Functions_in_Python.pdf', 'total_pages': 2, 'format': 'PDF 1.5', 'title': \"John Doe's CV\", 'author': 'John Doe', 'subject': '', 'keywords': '', 'moddate': '2025-11-13T03:37:16+00:00', 'trapped': '', 'modDate': 'D:20251113033716Z', 'creationDate': \"D:20251113033715+00'00'\", 'page': 1}, page_content='• Tools Used: C \\nCertifications \\n\\uf0b7 \\nMicrosoft Certified: Azure Developer Associate (AZ-204) \\nEducation \\nB.Tech in Computer Science and Engineering \\n2020 – 2024                \\nJain University \\n• Coursework: Computer Architecture, Comparison of Learning Algorithms, Computational Theory'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 0}, page_content='Context\\nEngineering\\nDesigning the systems that control what \\ninformation reaches the model and how it \\nmaintains coherence.'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 1}, page_content='Introduction\\nThe Evolution: From Prompts to Actions\\nThe Orchestration Challenge\\nThe Next Frontier of Tool Use\\nThe Future of AI Engineering\\nTools\\nSummary\\nWhat Are Agents?\\n01\\n04\\n05\\n07\\n08\\n10\\n11\\n12\\n13\\n25\\n26\\n26\\n27\\n29\\n31\\n35\\n36\\n39\\n40\\n15\\n17\\n18\\n20\\n23\\nWhat Is Context Engineering?\\nThe Context Window Challenge\\nStrategies and Tasks for Agents\\nWhere Agents Fit in Context Engineering\\nAgents\\nA Guide to Chunking Strategies\\nSimple Chunking Strategies\\nAdvanced Chunking Strategies\\nPre-Chunking vs. Post-Chunking\\nSummary\\nRetrieval\\nThe Architecture of Agent Memory\\nKey Principles for Effective Memory Management\\nMemory\\nQuery Augmentation\\nQuery Rewriting\\nQuery Expansion\\nQuery Decomposition\\nQuery Agents\\nTable of Contents\\nPrompting Techniques\\nClassic Prompting Techniques\\nAdvanced Prompting Techniques\\nPrompting for Tool Usage\\nUsing Prompt Frameworks\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 2}, page_content=\"Introduction\\nEvery developer who builds with Large Language Models (LLMs) eventually hits the same \\nwall. You start with a powerful model that can write, summarize, and reason with \\nstunning capability. But when you try to apply it to a real-world problem, the cracks start \\nto appear. It can't answer questions about your private documents. It has no knowledge \\nof events that happened yesterday. It confidently makes things up when it doesn't know \\nan answer.\\nAdd to \\nmemory\\nUser\\nLong-Term Memory\\nInput\\nAgent\\nShort-Term Memory\\nPrompt\\nDatabases\\nMCP\\nAnswer\\n1\\n3\\n2\\n4\\n7\\n8\\n6\\n5\\nAction Tools\\nRAG\\nVector search \\n(retrieval)\\nAgentic coordination \\n& decision making\\nUpdate prompt \\nwith answer\\nStore all context in \\nchat history\\nThe system that gives your \\napplication a sense of history and \\nthe ability to learn from interactions.\\nMemory\\nThe problem isn't the model's intelligence. The \\nproblem is that it's fundamentally disconnected. \\nIt's a powerful\\xa0but\\xa0isolated brain, with no access \\nto your specific data, the live internet, or even a \\nmemory of your last conversation. This isolation \\nis a direct result of its core architectural limit: \\nthe\\xa0context window. The context window is the \\nmodel's active working memory—the finite \\nspace where it holds the instructions and \\ninformation for the current task. Every word, \\nnumber, and piece of punctuation consumes \\nspace in this window. Just like a whiteboard, \\nonce it’s full, older information gets erased to \\nmake room for new instructions, and important \\ndetails can be lost.\\nYou can't fix this fundamental limitation by just \\nwriting better prompts. You have to build a \\nsystem around the model.\\nThat is\\xa0Context Engineering.\\nContext \\nEngineering \\nis \\nthe \\ndiscipline \\nof \\ndesigning the architecture that feeds an LLM \\nthe right information at the right time. It’s not \\nabout changing the model itself, but about \\nbuilding the bridges that connect it to the \\noutside \\nworld, \\nretrieving \\nexternal \\ndata, \\nconnecting it to live tools, and giving it a \\nmemory to ground its responses in facts, not \\njust its training data.\\nThis ebook is the blueprint for that system. We \\nwill cover the core components required to turn \\na brilliant but isolated model into a reliable, \\nproduction-ready application.\\nMastering these components is the difference \\nbetween a reasonable demo and a truly \\nintelligent system. Let's get to work.\\nThe decision-making brain that \\norchestrates how and when to use \\ninformation.\\nAgents\\nThe art of translating messy, \\nambiguous user requests into \\nprecise, machine-readable intent.\\nQuery \\nAugmentation\\nThe bridge connecting the LLM to \\nyour specific documents and \\nknowledge bases.\\nRetrieval \\nThe skill of giving clear, effective \\ninstructions to guide the model's \\nreasoning.\\nPrompting \\nTechniques\\nThe hands that allow your \\napplication to take direct action and \\ninteract with live data sources.\\nTools\\n01\\n02\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 3}, page_content='Agents\\nAs soon as you start building real systems with large language models, you run into the \\nlimits of static pipelines. A fixed recipe of “retrieve, then generate” works fine for simple \\nRetrieval Augmented Generation (RAG) setups, but it falls apart once the task requires \\njudgment, adaptation, or multi-step reasoning.\\nThis is where agents come in. In the context of context engineering, agents manage how \\n(and how well) information flows through a system. Instead of blindly following a script, \\nagents can evaluate what they know, decide what they still need, select the right tools, \\nand adjust their strategy when things go wrong.\\nAgents are both the architects of their contexts and the users of those contexts. \\nHowever, they need good practices and systems to guide them, because managing \\ncontext well is difficult, and getting it wrong quickly sabotages everything else the agent \\ncan do.\\nThinking...\\nUser\\nPrompt\\nResponse\\nAI Agent\\nThe term \"agent\" gets used broadly, so let’s define it in the context of building with large \\nlanguage models (LLMs). An AI agent is a system that can:\\nWhat Are Agents?\\nAttempt to handle all tasks themselves, which \\nworks well for moderately complex workflows.\\nSingle-Agent Architecture\\nDistribute work across specialized agents per \\ntask. Allows for complex workflows but introduces \\ncoordination challenges.\\nMulti-Agent Architecture\\nRetrieved \\ninformation \\nrelevant?\\nEach \\nsub-query\\nUser \\nquery\\nMemory\\nResponse\\nDecompose \\nquery into \\nsub-queries\\nQuery routing \\n& processing \\nSearch \\ntools\\nGenerate \\nresponse\\nYES\\nYES\\nNO\\nNO\\nYES\\nNO\\nAdditional \\ninformation \\nrequired?\\nAnswered \\nbefore?\\nMake dynamic decisions about information \\nflow. Rather than following a predetermined \\npath, agents decide what to do next based \\non what they\\'ve learned.\\nMaintain state across multiple interactions. \\nUnlike simple Q&A systems, agents \\nremember what they\\'ve done and use that \\nhistory to inform future decisions.\\nUse tools adaptively. They can \\nselect from available tools and \\ncombine them in ways that \\nweren’t explicitly programmed.\\nModify their approach based \\non results. When one strategy \\nisn’t working, they can try \\ndifferent approaches.\\n1\\n3\\n2\\n4\\nReasoning\\nLegend\\nTool Use\\nMemory\\n03\\n04\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 4}, page_content='This is one of the most critical parts of managing agentic systems. Agents don’t just need \\nmemory and tools; they also need to monitor and manage the quality of their own \\ncontext. That means avoiding overload, detecting irrelevant or conflicting information, \\npruning or compressing as needed, and keeping their in-context memory clean enough to \\nreason effectively.\\nContext Hygiene \\nLLMs have limited information capacity because the context window can only \\nhold so much information at once. This fundamental constraint shapes what \\nagents and agentic systems are currently capable of.\\nEvery time an agent is processing information, it needs to make decisions about:\\nThe Context Window Challenge\\nWhat information should remain \\nactive in the context window\\nWhat should be stored externally \\nand retrieved when needed\\nWhat can be summarized or \\ncompressed to save space\\nHow much space to reserve for \\nreasoning and planning\\nIt’s tempting to assume that bigger context windows solve this \\nproblem, but this is simply not the case. Longer contexts (hundreds of \\nthousands or even ~1M tokens) actually introduces new failure modes. \\nPerformance often begins to degrade far before the model reaches \\nmaximum token capacity, where agents will become confused, have \\nhigher rates of hallucination, or simply stop performing at the level \\nthey’re normally capable of. This isn’t just a technical limitation, it’s a \\ncore design challenge of any AI app.\\nContext Distraction \\nThe agent becomes burdened by too much \\npast information—history, tool outputs, \\nsummaries—and over-relies on repeating \\npast behavior rather than reasoning fresh.\\nContext Confusion \\nIrrelevant tools or documents crowd the \\ncontext, distracting the model and causing \\nit to use the wrong tool or instructions.\\nContext Clash \\nContradictory information within the \\ncontext misleads the agent, leaving it \\nstuck between conflicting assumptions.\\nContext\\nContext\\nContext Poisoning \\nIncorrect or hallucinated information \\nenters the context. Because agents \\nreuse and build upon that context, \\nthese errors persist and compound.\\nHere are some common types of errors that begin to happen or increase \\nas context window size grows:\\nContext\\n05\\n06\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 5}, page_content='Quality Validation: \\nChecking whether \\nretrieved information is \\nconsistent and useful.\\nContext Summarization: \\nPeriodically compressing \\naccumulated history into \\nsummaries to reduce \\nburden while preserving \\nkey knowledge.\\nContext Pruning: \\nActively removing \\nirrelevant or outdated \\ncontext, either with \\nspecialized pruning models \\nor a dedicated LLM tool.\\nContext Offloading: Storing details \\nexternally and retrieving them only \\nwhen needed, instead of keeping \\neverything in active context.\\nFailed\\nChange strategy\\nAdaptive Retrieval Strategies: \\nReformulating queries, switching \\nknowledge bases, or changing chunking \\nstrategies when initial attempts fail.\\nDynamic Tool Selection: Instead of dumping \\nevery possible tool into the prompt, agents \\nfilter and load only those relevant to the task. \\nThis reduces confusion and improves accuracy.\\nMulti-Source Synthesis: \\nCombining information from \\nmultiple sources, resolving \\nconflicts, and producing \\ncoherent answers.\\nStrategies and \\nTasks for Agents\\nAgents are able to effectively orchestrate context \\nsystems because of their ability to reason and \\nmake decisions in a dynamic way. Here are some \\nof the most common tasks agents are built for \\nand employ to manage contexts.\\nAgents serve as coordinators in your context engineering system. They don’t replace the \\ntechniques covered in other sections, instead, they orchestrate them intelligently. An \\nagent might apply query rewriting when initial searches are unsuccessful, choose \\ndifferent chunking strategies based on the type of content it encounters, or decide when \\nconversation history should be compressed to make room for new information. They \\nprovide the orchestration layer needed to make dynamic, context-appropriate decisions \\nabout information management.\\nWhere Agents Fit in Context Engineering\\nDifferent types of agents and functions within a context engineering system:\\nVector DB Episodic \\nand Factual Store\\nLONG TERM MEMORY\\nshort TERM MEMORY\\nMEMORY\\nPlanning \\nRoute to \\nSpecialized\\nData Collection \\nSelector\\nRetriever \\nTool Router\\nQuery Rewriter \\nAnswer \\nSynthesizer \\nCompressor\\nWorking Memory\\nTools and APIs\\nVector DB \\nKnowledge \\nCollections\\nWeb and Search \\nAPIs\\nEXTERNAL KNOWLEDGE \\nSOURCES\\nCAPABILITIES AND \\nKNOWLEDGE SOURCES\\nSUPERVISORS\\nSPECIALIZED AGENTS\\nGenerate Final \\nResponse\\nSend Context \\nfor Synthesis\\nRefine Query\\nReturn Tool \\nResults\\nReturn \\nRetrieved \\nFacts\\nSync \\nEpisodic \\nMemory\\nQuery and Update\\nSend Retrieval \\nRequest\\n07\\n08\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 6}, page_content='Query rewriting transforms the original user query into a more effective version for \\ninformation retrieval. Instead of just doing retrieve-then-read, applications now do a \\nrewrite-retrieve-read approach. This technique restructures oddly written questions so \\nthey can be better understood by the system, removes irrelevant context, introduces \\ncommon keywords that improve matching with correct context, and can split complex \\nquestions into simpler sub-questions.\\nQuery Rewriting\\nHow do i make \\nthis work when \\nmy api call keeps \\nfailing?\\nquery=”API call failure, \\ntroubleshooting \\nauthentication headers, \\nrate limiting, network \\ntimeout, 500 error”\\nRaw Query\\nQuery Re-writer (LLM)\\nRewritten Query\\nRAG applications are sensitive to the phrasing and specific \\nkeywords of the query, so this technique works by:\\nRestructuring \\nUnclear Questions:\\nContext \\nRemoval:\\nKeyword \\nEnhancement:\\nTransforms vague or \\npoorly formed user \\ninput into precise, \\ninformation-dense \\nterms.\\nEliminates irrelevant \\ninformation that \\ncould confuse the \\nretrieval process.\\nIntroduces common \\nterminology that \\nincreases the \\nlikelihood of matching \\nrelevant documents.\\nQuery \\nAugmentation\\nOne of the most important steps of context engineering is how you prepare and present \\nthe user\\'s query. Without knowing exactly what the user is asking, the LLM cannot \\nprovide an accurate response.\\nThough this sounds simple, it\\'s actually quite complex. There are two main issues to think \\nabout:\\nRemember that query augmentation addresses the \"garbage in, garbage out\" problem at \\nthe very start of your pipeline. No amount of sophisticated retrieval algorithms, advanced \\nreranking models, or clever prompt engineering can fully compensate for misunderstood \\nuser intent.\\nUsers often don\\'t interact with \\nchatbots or inputs in the ideal way.\\nDifferent parts of the pipeline need to \\ndeal with the query in different ways.\\nMany product builders will often develop \\nand test chatbots with queries that provide \\nthe request and all additional information \\nthat the LLM would need to understand the \\nquestion \\nin \\na \\nsuccinct, \\nperfectly \\npunctuated, clear way. Unfortunately, in the \\nreal world, user interactions with chatbots \\ncan be unclear, messy, and not complete. In \\norder to build robust systems, it\\'s important \\nto implement solutions that deal with all \\ntypes of interactions, not just ideal ones.\\nA question that an LLM could understand \\nwell might not be the best format to search \\nthrough a vector database with. Or, a query \\nterm that works best for a vector database \\ncould be incomplete for an LLM to answer. \\nTherefore, we need a way to augment the \\nquery that suits different tools and steps \\nwithin the pipeline.\\n1\\n2\\n09\\n10\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 7}, page_content=\"Query expansion enhances retrieval by generating multiple related queries from a single \\nuser input. This approach improves results when user queries are vague, poorly formed, \\nor when you need broader coverage, such as with keyword-based retrieval systems.\\nQuery Expansion\\nHowever, query expansion comes with challenges \\nthat need careful management:\\nQuery Drift:\\nOver-Expansion:\\nComputational \\nOverhead:\\nExpanded queries \\nmay diverge from the \\nuser's original intent, \\nleading to irrelevant or \\noff-topic results.\\nAdding too many \\nterms can reduce \\nprecision and retrieve \\nexcessive irrelevant \\ndocuments.\\nProcessing multiple \\nqueries increases \\nsystem latency and \\nresource usage.\\nOpen source \\nNLP tools\\nNatural language processing tools\\nFree nlp libraries\\nOpen source language processing platforms\\nNLP software with open source code\\nQuery Re-Writer (LLM)\\nRaw Query\\nExpanded Queries\\nQuery decomposition breaks down complex, multi-faceted questions into simpler, \\nfocused sub-queries that can be processed independently. This technique is especially \\ngood for questions that require information from multiple sources or involve several \\nrelated concepts.\\nQuery Decomposition\\nAfter retrieval, the context engineering system must aggregate and synthesize results \\nfrom all sub-queries to generate a coherent, comprehensive answer to the original \\ncomplex query.\\nContext Window\\nDecomposition Phase:\\nAn LLM analyzes the original \\ncomplex query and breaks it into \\nsmaller, focused sub-queries. Each \\nsub-query targets a specific aspect \\nof the original question.\\nProcessing Phase:\\nEach sub-query is processed \\nindependently through the retrieval \\npipeline, allowing for more precise \\nmatching with relevant documents.\\nThe process typically involves two main stages:\\n11\\n12\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 8}, page_content=\"Finalize context\\nConstruct query\\nExecution\\nFinish\\nRetrieved \\ninformation \\nrelevant?\\nResponse\\nAnalysis: Use generative models (e.g. large language models) to analyze the \\ntask & the required queries. Determine the exact queries to perform.\\nGenerate a \\ntext \\nresponse?\\nYES\\nYES\\nNO\\nNO\\nUser query\\nSearch\\nAggregation\\nChoose collection\\nAnalysis\\nDynamic Query Construction: Rather than using predetermined query patterns, \\nthe agent constructs queries on-demand based on understanding both the user \\nintent and the data schema. This means it can add filters and adjust search \\nterms automatically to find the most relevant results in the database, as well as \\nchoosing to run searches, aggregations or even both at the same time for you. \\nQuery execution: Formulates and sends queries to the agent’s chosen \\ncollection or collections.\\nMulti-collection routing: The agent understands the structure of all of your \\ncollections, so it can intelligently decide which data collections to query based \\non the user's question.\\nEvaluation: The agent can evaluate the retrieved information within the \\ncontext of the original user query. If there is missing information, the agent \\ncan try a different knowledge source or new query. \\n(Op\\ntional) Response generation: Receive the results from the database, and use \\na generative model to generate the final response to the user’s prompt/query.\\nContextual awareness: The context may also include previous conversation \\nhistory, and any other relevant information. The agent can maintain \\nconversation context for follow-up questions.\\nVector database\\nCollection A\\nVector database\\nCollection B\\nQuery Agents are the most \\nadvanced \\nform \\nof \\nquery \\naugmentation, using AI agents \\nto intelligently handle the entire \\nquery \\nprocessing \\npipeline, \\ncombining \\nthe \\ntechniques \\nabove. \\nA query agent takes a user’s \\nprompt/question \\nin \\nnatural \\nlanguage and decides the best \\nway to structure the query \\nbased on it’s knowledge of the \\ndatabase and data structure, \\nand can iteratively decide to re-\\nquery and adjust based on the \\nresults returned.\\nQuery Agents\\n13\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 9}, page_content=\"A Large Language Model is only as good as the information it can access. While LLMs are \\ntrained on massive datasets, they lack knowledge of your specific, private documents \\nand any information created after their training was completed. To build truly intelligent \\napplications, you need to feed them the right external information at the right time. This \\nprocess is called Retrieval. Pre-Retrieval and Retrieval steps make up the first parts of \\nmany AI architectures that rely on context engineering, such as Retrieval Augmented \\nGeneration (RAG). \\nPre-Retrieval\\nQuery\\nContext\\nResponse\\nVector Database\\nPrompt Template\\nEmbedding Model\\nLLM\\nChunks\\nDocuments\\nRetrieval\\nRetrieval\\nThe challenge is simple in concept but tricky in practice: a raw dataset of documents is \\nalmost always too large to fit into an LLM's limited context window (the inputs given to an \\nAI model). We can't just hand the model an entire set of user manuals or research papers. \\nInstead, we must find the\\xa0perfect piece\\xa0of those documents, the single paragraph or \\nsection that contains the answer to a user's query.\\nTo make our vast knowledge bases searchable and find that perfect piece, we must first \\nbreak our documents down into smaller, manageable parts. This foundational process, \\nknown as\\xa0chunking, is the key to successful retrieval.\\nChunking is the most important decision you will make for your retrieval system's \\nperformance. It is the process of breaking down large documents into smaller, \\nmanageable pieces. Get it right, and your system will be able to pinpoint relevant facts \\nwith surgical precision. Get it wrong, and even the most advanced LLM will fail.\\nA Guide to Chunking Techniques\\nPost-Chunking\\nChunks\\nLearn how chunking strategies can help improve your RAG performance and explore different chunking \\nmethods. Read the complete blog post here: weaviate.io/blog/chunking-strategies-for-rag\\nDocument\\nChunk\\nThe Context Window\\nSystem prompt\\nUser query\\nRelevant chunks\\nYou are a helpful AI assistant...\\nWhat is a vector database?\\nDoc 1; Chunk 1\\nDoc 2; Chunk 1\\nDoc 2; Chunk 2\\nDoc 3; Chunk 1\\n14\\n15\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 10}, page_content='When designing your chunking strategy, you must balance two competing priorities:\\nRetrieval Precision:\\xa0Chunks need to be small and focused on a single idea. This \\ncreates a distinct, precise embedding, making it easier for a vector search system to \\nfind an exact match for a user\\'s query. Large chunks that mix multiple topics create \\n\"averaged,\" noisy embeddings that are hard to retrieve accurately.\\nContextual Richness:\\xa0Chunks must be large and self-contained enough to be \\nunderstood. After a chunk is retrieved, it is passed to the LLM. If the chunk is just an \\nisolated sentence without context, even a powerful model will struggle to generate a \\nmeaningful response.\\nThe goal is to find the\\xa0\"chunking sweet spot\", creating chunks that are small enough for \\nprecise retrieval but complete enough to give the LLM the full context it needs.\\nYour choice of strategy will depend on the nature of your documents and the needs of \\nyour application.\\nContextual richness\\nlow\\nhigh\\nhigh\\nRetrieval precision\\nRich but Unfindable\\nOversized chunks that contain \\nthe answer but have \"noisy\" \\nembeddings, making them \\nimpossible for the retrieval \\nsystem to find accurately.\\nThe Sweet Spot (Optimal Chunks)\\nSemantically complete paragraphs \\nthat are focused enough to be \\nfound and rich enough to be \\nunderstood.\\nPrecise but Incomplete\\nOverly small chunks (e.g., \\nsingle sentences) that are easy \\nto find but lack the context for \\nthe LLM to generate a good \\nresponse.\\nThe Failure Zone\\nPoorly constructed, random \\nchunks that are neither \\nfindable nor useful, the worst \\nof both worlds.\\nThe Chunking Strategy Matrix\\nRecursive Chunking:\\xa0A more intelligent approach that splits text using a prioritized list of \\nseparators (like paragraphs, then sentences, then words). It respects the document\\'s \\nnatural structure and is a solid default choice for unstructured text.\\nDocument-Based Chunking:\\xa0This method uses the document\\'s inherent structure. For \\nexample, it splits a Markdown file by its headings (#,\\xa0##), an HTML file by its tags \\n(<p>,\\xa0<div>), or source code by its functions.\\nThis connection challenges our understanding of space \\nand time. When you measure one entangled particle, the \\nother\\'s state changes instantly.\\nQuantum entanglement is a key concept in quantum \\nphysics. It occurs when particles become linked, so the \\nstate of one instantly affects the state of another, no \\nmatter the distance between them\\nIf chunks are too big, split again using the \\nnext separator\\nSplit the text using the highest-level separator\\nRepeat until all chunks fit within the desired \\nsize while preserving meaning\\nDefine a hierarchy of separators \\n(e.g., paragraphs → sentences → words)\\n1\\n2\\n3\\n4\\nVectorize each unit as a standalone chunk\\nGroup content under each boundary into \\ncohesive units\\nStore chunks with metadata linking them \\nto their source document and section\\nIdentify logical document boundaries \\n(e.g., chapters, sections, headings)\\n1\\n2\\n3\\n4\\n# Heading  This is a heading. --## Subheading  This is a\\nsubheading. We can continue with more content here. -- \\n## This is a second subheading  Here is different content.\\nchunk 2\\nchunk 3\\nchunk 1\\nPhotosynthesis is one of nature\\'s most vital processes.\\noverlap\\noverlap\\nSimple Chunking Techniques\\nFixed-Size Chunking:\\xa0The simplest method. The text is split into chunks of a \\npredetermined size (e.g., 512 tokens). It\\'s fast and easy but can awkwardly cut sentences \\nin half. Using an overlap (e.g., 50 tokens) between chunks helps mitigate this.\\n16\\n17\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 11}, page_content=\"Late Chunking:\\xa0An architectural pattern that inverts the standard process. It embeds \\nthe\\xa0entire document\\xa0first to create token-level embeddings with full context. Only then is \\nthe document split into chunks, with each chunk's embedding derived from these pre-\\ncomputed, context-rich tokens.\\nHierarchical Chunking:\\xa0Creates multiple layers of chunks at different levels of detail (e.g., \\ntop-level summaries, mid-level sections, and granular paragraphs). This allows a retrieval \\nsystem to start with a broad overview and then drill down into specifics as needed.\\nTitle\\nAbstract\\nIntro\\nIntro\\nMethod\\nReference\\nChunk 3\\nDocuments\\nTitle\\nReference\\nChunk 5\\nMethod\\nChunk 4\\nAbstract\\nChunk 2\\nChunk 1\\n“Alice went for a walk in the woods one day \\nand on her walk, she spotted something. She \\nsaw a rabbit hole at the base of a large tree. \\nShe fell into the hole and found herself in a \\nstrange new world.”\\nEmbedding Model\\n1\\n2\\n3\\n4\\nEmbed the entire document using a \\nlong-context model to generate \\ntoken-level embeddings.\\nPreserve context because the \\nembeddings were created with full \\ndocument context, each token \\npreserves its relationship to tokens in \\nneighboring chunks. \\nPool strategically instead of pooling all \\ntokens into one vector, late chunking \\npools tokens according to your chunking \\nstrategy to get multiple contextually-\\naware embeddings per document.\\nChunk the token embeddings \\n(instead of the raw text).\\nLLM-Based Chunking:\\xa0Uses a Large Language Model to intelligently process a document \\nand generate semantically coherent chunks. Instead of relying on fixed rules, the LLM can \\nidentify logical propositions or summarize sections to create meaning-preserving pieces.\\nAgentic Chunking:\\xa0This takes the concept a step further then LLM-Based Chunking. An AI \\nagent dynamically analyzes a document's structure and content to select the\\xa0best\\xa0chunking \\nstrategy (or combination of strategies) to apply for that specific document.\\nSemantic Chunking:\\xa0Instead of using separators, this technique splits text based on \\nmeaning. It groups semantically related sentences together and creates a new chunk \\nonly when the topic shifts, resulting in highly coherent, self-contained chunks.\\nAdvanced Chunking Techniques\\nThe water cycle is a continuous process by which water moves \\nthrough the Earth and atmosphere. It involves processes such as \\nevaporation, condensation, precipitation, and collection. Evaporation \\noccurs when the sun heats up water in rivers, lakes, or oceans, \\nturning it into vapor or steam. This vapor rises into the air and cools \\ndown, forming clouds. Eventually, the clouds become heavy and \\nwater falls back to the earth as precipitation, which can be rain, \\nsnow, sleet, or hail. This water then collects in bodies of water, \\ncontinuing the cycle.\\nCalculate cosine distance between all pairs\\nVectorize windows of sentences\\nMerge until breakpoint is reached\\nSplit text into sentences or paragraphs\\n1\\n2\\n3\\n4\\nAlex loves reading.\\nAlex visited the library.\\nAlex visited the library. \\nHe loves reading.\\nPropositions\\nInput text\\nLLM\\nMarkdown\\nHTML\\nPDF\\nDocx\\nDocx\\nDocuments\\nSelecting Method\\nChunks\\nOptimized \\nChunks\\nAnalyzes document \\nformat and content\\nSemantic Chunking\\nDocument-based Chunking\\nFixed-size Chunking\\nHybrid \\nApproach\\n18\\n19\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 12}, page_content=\"Beyond\\xa0how\\xa0you chunk, a key system design choice is\\xa0when\\xa0you chunk. This decision \\nleads to two primary architectural patterns.\\nPre-Chunking vs. Post-Chunking\\nPre-Chunking\\nPre-Processing\\nRetrieval by semantic similarity\\nVector Database\\nEmbedded Chunks\\nRetrieved Context\\nAugmented\\nGeneration\\nQuery\\nOutput\\nDocuments\\nChunks\\nEmbedding Model\\nLarge Language Model\\nPrompt Template\\nClean text (remove headers, \\nfooters, special characters, etc.)\\nSplit documents into smaller chunks (e.g., 500 tokens \\nper chunk, semantic chunks, hierarchical chunks).\\nThe most common method, where all data processing happens upfront and offline, \\nbefore any user queries come in.\\nPre-Chunking\\nWorkflow\\nRetrieval is extremely fast at query \\ntime because all the work has already \\nbeen done. The system only needs to \\nperform a quick similarity search.\\nThe chunking strategy is fixed. If you \\ndecide to change your chunk size or \\nmethod, you must re-process your \\nentire dataset.\\nPRO\\nCON\\nClean Data -> Chunk Documents -> Embed & Store Chunks\\nAn advanced, real-time alternative where chunking happens\\xa0after\\xa0a document has been \\nretrieved, in direct response to a user's query.\\nPost-Chunking\\nWorkflow\\nIt's highly flexible. You can create \\ndynamic chunking strategies that are \\nspecific to the context of the user's \\nquery, potentially leading to more \\nrelevant results.\\nIt adds latency. The chunking \\nprocess happens in real-time, making \\nthe first response slower for the end-\\nuser. It also requires more complex \\ninfrastructure to manage.\\nPRO\\nCON\\nPre-Processing\\nRetrieval by semantic similarity\\nVector Database\\nRetrieve full documents, then chunk and rerank before adding \\nto LLM context window. Store chunked documents.\\nPost-Chunking\\nRetrieved Context\\nAugmented\\nGeneration\\nQuery\\nOutput\\nDocuments\\nEmbedding Model\\nLarge Language Model\\nPrompt Template\\nClean text (remove headers, \\nfooters, special characters, etc.)\\nChunks\\nWe built a post-chunking strategy into Elysia, our open source agentic RAG framework. \\nYou can read more about that here: \\nhttps://weaviate.io/blog/elysia-agentic-rag#chunk-on-demand-smarter-document-processing\\nStore Documents -> Retrieve Relevant Document -> Chunk Dynamically\\n20\\n21\\nContext engineering\"),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 13}, page_content='Guide to Choosing Your Chunking Strategy\\nChunking \\nStrategy\\nFixed-Size\\nRecursive\\nDocument-\\nBased\\nSemantic\\nLLM-Based\\nAgentic\\nLate \\nChunking\\nHierarchical\\nHow It Works\\nSplits by token or \\ncharacter count.\\nSplits text by \\nrepeatedly dividing \\nit until it fits the \\ndesired chunk size, \\noften preserving \\nsome structure.\\nSplits only at \\ndocument \\nboundaries or by \\nstructural elements \\nlike headers.\\nSplits text at natural \\nmeaning boundaries \\n(topics, ideas).\\nUses a language \\nmodel to decide \\nchunk boundaries \\nbased on context \\nand meaning.\\nLets an AI agent \\ndecide how to split \\nbased on meaning \\nand structure.\\nEmbeds the whole \\ndocument first, then \\nderives chunk \\nembeddings from it.\\nBreaks text into \\nmultiple levels \\n(sections → \\nparagraphs → \\nsentences).\\nSmall or simple \\ndocs, or when speed \\nmatters most.\\nDocuments where \\nsome structure \\nshould be \\nmaintained but \\nspeed is still \\nimportant.\\nCollections of \\nshort, standalone \\ndocuments or \\nhighly structured \\nfiles.\\nTechnical, academic, \\nor narrative \\ndocuments where \\ntopics shift without \\nclear separators.\\nComplex text where \\nmeaning-aware \\nchunking improves \\ndownstream tasks \\nlike Q&A.\\nComplex, nuanced \\ndocuments that \\nrequire custom \\nstrategies.\\nUse cases where \\nchunks need \\nawareness of the full \\ndocument\\'s context.\\nLarge, structured \\ndocuments where \\nboth summary and \\ndetail are needed.\\nMeeting notes, \\nshort blog posts, \\nemails, simple FAQs.\\nResearch articles, \\nproduct guides, \\nshort reports.\\nNews articles, \\ncustomer support \\ntickets, Markdown \\nfiles.\\nScientific papers, \\ntextbooks, novels, \\nwhitepapers.\\nLong reports, legal \\nopinions, medical \\nrecords.\\nRegulatory filings, \\nmulti-section \\ncontracts, \\ncorporate policies.\\nCase studies, \\ncomprehensive \\nmanuals, long-form \\nanalysis reports.\\nEmployee \\nhandbooks, \\ngovernment \\nregulations, \\nsoftware \\ndocumentation.\\nComplexity\\nBest For\\nExamples\\nThe effectiveness of your Retrieval Augmentation system is not determined by a single \\n“magic” bullet, but by a series of deliberate engineering choices. The quality of the \\ncontext you provide to an LLM is a direct result of two key decisions:\\nSummary\\nThe Chunking Strategy\\nThe Architectural Pattern\\nThe method you choose to break \\ndown your documents.\\nThe point at which you perform \\nthe chunking.\\nThe \"How\"\\nThe \"When\"\\nMastering these two elements is fundamental to context engineering. A well-designed \\nretrieval system is the difference between an LLM that guesses and one that provides \\nfact-based, reliable, and contextually relevant answers.\\n22\\n23\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 14}, page_content='Prompting \\nTechniques\\nPrompt engineering is the practice of designing, refining, and optimizing inputs (prompts) \\ngiven to Large Language Models (LLMs) to get your desired output. The quality and \\neffectiveness of LLMs are heavily influenced by the prompts they receive, and the way \\nyou phrase a prompt can directly affect the accuracy, usefulness, and clarity of the \\nresponse.\\nIt’s essentially about interacting with AI efficiently: giving it instructions, examples, or \\nquestions that guide the model toward the output you need.\\nIn this section, we’ll go over prompting techniques that are essential for improving \\nRetrieval-Augmented Generation (RAG) applications and overall LLM performance.\\nImportant Note: Prompt engineering focuses on how you phrase \\ninstructions for the LLM. Context engineering, on the other \\nhand, is about structuring the information and knowledge you \\nprovide to the model, such as retrieved documents, user \\nhistory, or domain-specific data, to maximize the model’s \\nunderstanding and relevance. Many of the techniques below \\n(CoT, Few-shot, ToT, ReAct) are most effective when combined \\nwith well-engineered context.\\nThis technique involves asking the model \\nto “think step-by-step” and break down \\ncomplex \\nreasoning \\ninto \\nintermediate \\nsteps. This is especially helpful when \\nretrieved documents are dense or contain \\nconflicting \\ninformation \\nthat \\nrequires \\ncareful \\nanalysis. \\nBy \\nverbalizing \\nits \\nreasoning process, the LLM can come at \\nmore accurate and logical conclusions.\\nChain of Thought \\nThis approach provides the LLM with a \\nfew examples in the context window that \\ndemonstrate the type of output or \\n“golden” answers you want. Showing \\nexamples helps the model understand \\nthe desired format, style, or reasoning \\napproach, improving response accuracy \\nand relevance, especially for specialized \\nor technical domains.\\nFew-Shot Prompting\\nCombining CoT and Few-shot examples is a powerful way to guide both the model’s \\nreasoning process and its output format for maximum efficiency.\\nClassic Prompting Techniques\\nPrompt\\nResponse\\nInput\\nDesired \\noutcome\\nExample\\nInput\\nDesired \\noutcome\\nExample\\nLLM: pattern recognition \\n(format, style, logic)\\nInput\\nDesired \\noutcome\\nExample\\n...\\nResponse\\nPrompt\\nThought\\nThought\\nPro Tip #1:\\xa0\\nPro Tip #2:\\xa0\\nMake the model reasoning in Chain of \\nThought very specific to your use-case. \\nFor example, you might ask the model to:\\nMaximize efficiency and reduce \\ntoken count, asking the model to \\nreason in a \"draft\" form, using no \\nmore than 5 words per sentence. \\nThis makes sure that the model\\'s \\nthought process is visible while \\nreducing output token count.\\nE valuate the environment\\nRepeat any relevant information\\nExplain the importance of this information \\nto the current request\\n24\\n25\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 15}, page_content='Building on classic techniques, advanced strategies guide LLMs in more sophisticated ways:\\nAdvanced Prompting Strategies\\nToT builds on CoT by instructing the model \\nto explore and evaluate multiple reasoning \\npaths in parallel, much like a decision tree. \\nThe model can generate several different \\nsolutions to a problem and choose the best \\nresult. This is especially useful in RAG \\nwhen there are many potential pieces of \\nevidence, and the model needs to weigh \\ndifferent possible answers based on \\nmultiple retrieved documents.\\nTree of Thoughts (ToT):\\xa0\\nPrompting for Tool Usage\\nWhen your LLM interacts with external tools, clear prompting ensures correct tool \\nselection and usage.\\nDefining Parameters and Execution Conditions\\nLLMs can sometimes make incorrect tool selections or \\nuse tools in suboptimal ways. To prevent this, prompts \\nshould clearly define:\\nExamples:\\xa0Include few-shot examples \\nshowcasing correct tool selection and \\nusage for various queries. For instance:\\nUser Query: \\n\"What\\'s the weather like in Paris?\" -> \\nUse Weather_API with city=\"Paris\"\\nUser Query: \\n\"Find me a restaurant near the Eiffel \\nTower.\" -> Use Restaurant_Search_Tool \\nwith location=\"Eiffel Tower\"\\nWhen to use a tool:\\xa0\\nSpecify scenarios or \\nconditions that trigger \\na particular tool.\\nHow to use a  tool:\\xa0\\nProvide expected \\ninputs, parameters, and \\ndesired outputs.\\nThis framework combines CoT with agents, \\nenabling the model to \"Reason\" (think) and \\n\"Act\" dynamically. The model generates both \\nreasoning traces and actions in an interleaved \\nmanner, allowing it to interact with external \\ntools or data sources and adjust its reasoning \\niteratively. ReAct can improve RAG pipelines by \\nenabling LLMs to interact with retrieved \\ndocuments in real time, updating reasoning \\nand actions based on external knowledge to \\ngive more accurate and relevant responses.\\nReAct Prompting:\\nIf you are building a project that requires extensive prompting or want to systematically \\nimprove your LLM results, you could consider using frameworks like: DSPy, Llama \\nPrompt Ops, Synalinks.\\nThat said, you don’t necessarily need to use a framework. Following the prompting \\nguidelines outlined (clear instructions, Chain of Thought, Few-shot Learning, and \\nadvanced strategies) can achieve highly effective results without additional frameworks.\\nThink of these frameworks as optional helpers for complex projects, not a requirement \\nfor everyday prompt engineering.\\nUsing Prompt Frameworks\\nThis very precise guidance,\\xa0which should be included as part of your overall tool \\ndescription, helps the LLM understand the exact boundaries and functionalities of each \\navailable tool, minimizing error, and improving overall system reliability.\\nPro Tip: How to Write an Effective Tool Description\\nThe LLM\\'s decision to use your tool depends entirely on its \\ndescription. Make it count:\\nUse an Active Verb:\\xa0Start with a clear action.\\xa0\\nget_current_weather\\xa0is better than\\xa0weather_data.\\nBe Specific About Inputs:\\xa0Clearly state what arguments \\nthe tool expects and their format (e.g.,\\xa0city (string), \\ndate (string, YYYY-MM-DD)).\\nDescribe the Output:\\xa0Tell the model what to expect in \\nreturn (e.g.,\\xa0returns a JSON object with \"high\", \"low\", \\nand \"conditions\".).\\nMention Limitations:\\xa0If the tool only works for a specific \\nregion or time frame, say so (e.g.,\\xa0Note: Only works for \\ncities in the USA.).\\n26\\n27\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 16}, page_content='Memory\\nWhen you\\'re building agents, memory isn\\'t just a bonus feature - it\\'s the very thing that \\nbreathes life into them. Without it, an LLM is just a powerful but stateless text processor \\nthat responds to one query at a time with no sense of history. Memory transforms these \\nmodels into something that feels more dynamic and, dare we say, more ‘human’, that’s \\ncapable of holding onto context, learning from the past, and adapting on the fly.\\nAndrej Karpathy gave us the perfect analogy when he compared an LLM’s context \\nwindow to a computer’s RAM and the model itself to the CPU. In this view, the context \\nwindow is the agent\\'s active consciousness, where all its \"working thoughts\" are held. \\nBut just like a laptop with too many browser tabs open, this RAM can fill up fast. Every \\nmessage, every tool output, every piece of information consumes precious tokens.\\nSource: Andrej Karpathy: Software Is Changing (Again)\\nThis is where context engineering becomes an art. The goal isn’t to shove more data into \\nthe prompt but to design systems that make the most of the active context window - \\nkeeping essential information within reach while gracefully offloading everything else \\ninto smarter, more persistent storage.\\nMemory in an AI agent is all about retaining information to navigate changing tasks, \\nremember what worked (or didn\\'t), and think ahead. To build robust agents, we need to \\nthink in layers, often blending different types of memory for the best results.\\nThe Architecture of Agent Memory\\nContext Offloading is the practice of storing information outside the LLM’s active context window, \\noften in external tools or vector databases. This frees up the limited token space so that only the most \\nrelevant info stays in context.\\nShort-Term Memory\\nUser:  “What’s the weather?”\\nAI: “It’s sunny, 24°C”\\nUser: “Should I bring a jacket?”\\nContext Window\\nAI:  “No need, it’s warm!”\\nShort-term memory is the agent\\'s \\nimmediate workspace. It\\'s the \"now,\" \\nstuffed into the context window to fuel \\non-the-fly decisions and reasoning. This \\nis powered by in-context learning, where \\nyou pack recent conversations, actions, \\nor data directly into the prompt.\\nBecause it\\'s constrained by the model\\'s \\ntoken limit, the main challenge is \\nefficiency. And, the trick is to keep this \\nstreamlined to reduce costs and latency \\nwithout missing any details that might be \\nimportant for the next processing steps.\\nLong-Term Memory\\nLong-term memory moves past the immediate \\ncontext window, storing information externally \\nfor quick retrieval when needed. This is what \\nallows an agent to build a persistent \\nunderstanding of its world and its users over \\ntime. It\\'s commonly powered by Retrieval-\\nAugmented Generation (RAG), where the agent \\nqueries an external knowledge base (like a \\nvector database) to pull in relevant information.\\nThis memory can store different kinds of \\ninformation, like for example: episodic memory to \\nstore specific events or past interactions, or \\nsemantic memory that holds general knowledge \\nand facts. This could also be information from \\ncompany documents, product manuals, or a \\ncurated domain-knowledge base, allowing the \\nagent to answer questions with factual accuracy.\\nExternal Storage\\nEpisodic\\nSemantic\\nProcedural\\nVector \\nDatabase\\n28\\n29\\nContext engineering\\nCalculator Python\\nInterpreter Terminal\\nFile System\\n(+embeddings)\\nEthernet\\nDisk\\nRAM\\nCPU\\nOther LLMs\\nBrowser\\nSoftware 1.0 tools\\n“classical computer”\\nPeripheral devices I/O\\nLLM\\nContext\\nWindow\\nVideo\\nAudio'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 17}, page_content='In reality, most modern systems use a hybrid approach, blending short-term memory for \\nspeed with long-term memory for depth. Some advanced architectures even introduce \\nadditional layers:\\nWorking Memory: A temporary holding area for information related to a specific, \\nmulti-step task. For example, if an agent is booking a trip, its working memory might \\nhold the destination, dates, and budget until the task is complete, without cluttering \\nthe long-term store.\\nProcedural Memory: This helps an agent learn and master routines. By observing \\nsuccessful workflows, the agent can internalize a sequence of steps for a recurring \\ntask, making it faster and more reliable over time.\\nHybrid Memory Setup\\nQuery\\n“Book me a \\nflight to Tokyo \\nin December.”\\nRetrieve\\n“User preferences, \\ntravel domain \\nknowledge, \\nbooking routines, \\netc.”\\nTask State\\n“Store the task-\\nspecific state in \\nthe working \\nmemory”\\nContext Window\\nThought\\n“Need to check \\nbudget, dates, \\npreferences”\\nTool Call\\n“Flights API, \\nWeather API, \\nCalendar, etc.”\\nThought\\n“Review the \\ncontext & \\ndecide”\\n...\\nResponse\\n“Respond & then \\nclear the state & \\nupdate memory”\\nShort-Term Memory\\nWorking Memory\\nLong-Term Memory\\nA temporary scratchpad or buffer box.\\nImmediate reasoning space, bounded by context limit.\\nPersistent storage system to retain and recall \\ninformation across sessions.\\n\"task_id\": \"book_flight_001\"\\n\"task_type\": \"travel_booking\"\\n\"task_status\": \"in_progress\"\\n\"task_context\":\\n\"destination\": \"Tokyo\"\\n\"origin\": \"San Francisco\"\\n“tools_available”: “...”\\nTask Context\\n\"dates\":\\n\"departure\": \"2025-12-15\"\\n\"return\": \"2025-12-22\"\\n\"constraints\":\\n\"budget_max\": 1200,       \\n\"preferred_time\": \"morning\",     \\n\"preferred_airlines\": \\n[\"JAL\", \"ANA\"]\\nParameters\\n\"intermediate_results\":    \\n\"flights_found\": 12    \\n\"top_candidates\":      \\n\"flight\": \"JAL005\", \"price\": 1150, ...     \\n\"flight\": \"ANA106\", \"price\": 1180, ...   \\n\"next_steps\": [\"compare_amenities\", \"check_baggage_policy\", \\n\"confirm_selection\"]\\nNext Steps/Results\\n(general + domain knowledge)\\nSemantic Memory\\n(learned routines/decision workflows)\\nProcedural Memory\\nEpisodic Memory\\n(past events/interactions/preferences)\\nRetrieval\\nthe agent retrieves \\nrelevant knowledge to \\ninform its current \\ndecision like past travel \\npreferences, travel \\ndomain knowledge \\n(airlines, airport codes, \\nvisa rules, etc.), or \\nlearned workflows.\\nMemory Storage\\nafter an interaction, \\nor tool call, the agent \\nsaves important \\ninformation, new user \\npreferences, or \\nsuccessful outcomes/\\nworkflows to its \\npermanent memory \\nfor future use.\\n1\\n3\\n2\\n4\\nTask State Storage\\nthe agent sends \\nspecific, in-progress \\ntask details to a \\ntemporary scratchpad \\nto keep the main \\ncontext window from \\ngetting cluttered.\\nTask Context Recall \\nthe agent pulls the \\nrelevant task details \\nback into its active \\nreasoning space to \\ncontinue a multi-step \\nprocess.\\nEffective memory management can make or break an LLM agent. Poor memory practices \\nlead to error propagation, where bad information gets retrieved and amplifies mistakes \\nacross future tasks.\\nHere are some of the starting principles for getting things right:\\nKey Principles for Effective Memory \\nManagement\\nPrune and Refine Your Memories\\nMemory isn\\'t a write-once system. It needs regular maintenance. Periodically \\nscan your long-term storage to remove duplicate entries, merge related \\ninformation, or discard outdated facts. A simple metric for this could be the \\nrecency and retrieval frequency. If a memory is old and rarely accessed, it \\nmight be a candidate for deletion, especially in evolving environments where \\nold information can become a liability. \\nFor example, a customer support agent might automatically prune \\nconversation logs that are over 90 days old and marked as resolved, closed, \\nor no longer active in the memory. It could just retain the summaries (for trend \\ndetection and analysis) rather than full word-to-word transcripts.\\nPruned\\nMerged\\n30\\n31\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 18}, page_content='Be Selective About What You Store\\nNot every interaction deserves a permanent spot in long-term storage. One must \\nimplement some sort of filtering criteria to assess information for quality and \\nrelevance before saving it. A bad piece of retrieved information can often lead to \\ncontext pollution, where the agent repeatedly makes the same mistakes. One \\nway to prevent this is to have the LLM \"reflect\" on an interaction and assign an \\nimportance score before committing it to memory.\\nDeleted\\nTailor the Architecture to the Task\\nThere is no one-size-fits-all memory solution. A customer service bot needs a \\nstrong episodic memory to recall user history, while an agent that analyzes \\nfinancial reports needs a robust semantic memory filled with domain-specific \\nknowledge. Always start with the simplest approach that works (like a basic \\nconversational buffer with last ‘n’ queries/responses) and gradually layer in more \\nadvanced mechanisms as the use case demands it.\\nEpisodic \\nMemory\\nSemantic \\nMemory\\nOptional additions:\\nQuery \\nAugmentation\\nTools \\nQuery\\nOutput\\nUltimately, memory is what elevates LLM agents from simple responders to intelligent \\ncontext-aware systems. Effective memory isn’t simply a passive storage… It’s an active, \\nmanaged process! The goal is to build agents that don\\'t just\\xa0store\\xa0memory, but \\ncan\\xa0manage\\xa0it - knowing what to remember, what to forget, and how to use the past to \\nreason about the future.\\nMaster the Art of Retrieval\\nEffective memory is less about how much you can store and more about how well \\nyou can retrieve the right piece of information at the right time. A simple blind \\nsearch is often not enough, so advanced techniques like reranking (using an LLM \\nto re-order retrieved results for relevance) and iterative retrieval (refining/\\nexpanding a search query over multiple steps) can be used to improve the quality \\nof retrieved information.  \\nTools like the Query Agent and Personalization Agent offer these capabilities out \\nof the box, enabling searches across multiple collections and reranking based on \\nuser preferences and interaction history.\\nReranking\\nAdd to \\nContext\\nRetrieval\\nExpanded Queries\\n32\\n33\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 19}, page_content='Tools\\nIf memory gives an agent a sense of self, then tools are what give it superpowers. By \\nthemselves, LLMs are brilliant conversationalists and text manipulators, but they live \\ninside a bubble. They can\\'t check the current weather, book a flight, or look up real-time \\nstock prices. They are, by design, disconnected from the living, breathing world of data \\nand action.\\nThis is where tools come in. A \"tool\" is anything that connects an LLM agent to the \\noutside world, allowing it to take direct “action” in the real world and retrieve information \\nrequired to fulfill a task. Integrating tools elevates an agent from just being a \\nknowledgeable consultant to something that can actually get things done.\\nContext engineering for tools isn\\'t just giving an agent a list of APIs and instructions. It\\'s \\nabout creating a cohesive workflow where the agent can understand what tools are \\navailable, decide correctly which one to use for a specific task, and interpret the results \\nto move forward.\\nThe journey to modern tool use has been a rapid evolution. Initially, devs tried to get \\naction out of LLMs with good old prompt engineering by tricking the model into \\ngenerating text that looked like a command. It was clever but prone to errors.\\nThe real breakthrough was function calling, aka tool calling. This capability, now native to \\nmost models, allows an LLM to output structured JSON that can contain the name of a \\nfunction to call and the arguments to use.\\nWith this, there are a bunch of possibilities:\\nThe work of context engineering here is in how you present these tools. A well-written \\ntool description is like a mini-prompt that guides the model, making it crystal clear what \\nthe tool does, what inputs it needs, and what it returns.\\nThe Evolution: From Prompts to Actions\\nA travel agent bot can use a \\nsearch_flights tool, and when a \\nuser asks, \"Find me a flight to \\nTokyo next Tuesday,\" the LLM \\ndoesn\\'t guess the answer. It \\ngenerates a call to the function you \\nprovided, which in turn queries a \\nreal airline API.\\nFor a complex request like \"Plan a \\nweekend trip to San Francisco for \\nme,\" the agent might need to chain \\nseveral tools together: find_flights, \\nsearch_hotels, and \\nget_local_events. This requires the \\nagent to reason, plan, and execute \\na multi-step workflow.\\nA Simple Tool\\nA Chain of Tools\\nRepeat Until Goal Satisfied\\nQuery\\nResponse\\nObservation\\nAction\\nThought\\n34\\n35\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 20}, page_content='Giving an agent a tool is easy (mostly). Getting it to use that tool reliably, safely, and \\neffectively is where the real work begins. The central task of context engineering \\nis\\xa0orchestration, i.e., managing the flow of information and decision-making as the agent \\nreasons about which tool to use.\\nThis involves a few key steps that happen in the context window. Let’s break down these \\nkey orchestration steps using Glowe, a skincare domain knowledge app powered by our \\nElysia orchestration framework, as our running example.\\nThe Orchestration Challenge\\nTool Discovery:\\xa0The agent needs to know what tools it has at its disposal. This is \\nusually done by providing a list of available tools and their descriptions in the system \\nprompt. The quality of these descriptions is very critical. They are the agent\\'s only \\nguide to understanding what each tool does, allowing the model to understand when \\nto use a tool and, more importantly, when to avoid it.\\nIn Glowe, we configure a set of specialized tools (Step 5) with precise descriptions when initializing \\nevery new chat tree.\\nTool Selection and Planning (Thought):\\xa0When faced with a user request, the agent \\nmust reason about whether a tool is needed. If so, which one? For complex tasks, it \\nmight even need to chain multiple tools together, forming a plan (e.g., \"First, search \\nthe web for the weather; then, use the email tool to send a summary\").\\nHere, the decision agent correctly analyzed the incoming request and selected the product_agent tool.\\nA\\nrgument Formulation (Action):\\xa0Once a tool is selected, the agent must figure out \\nwhat arguments to pass to it. If the tool is\\xa0get_weather(city, date), the agent needs to \\nextract \"San Francisco\" and \"tomorrow\" from the user\\'s query and format them \\ncorrectly. This could also be a structured request or API call with the necessary \\ninformation to use the tool.\\nIn this case, the product_agent required a text query for searching the products collection. Notice \\nhow the agent also corrected itself (self-healing) after generating an ill-formed argument that initially \\ncaused an error (another key piece of orchestration).\\n36\\n37\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 21}, page_content='Reflection (Observation):\\xa0After executing the tool, the output (the \"observation\") is \\nfed back into the context window. The agent then reflects on this output to decide its \\nnext step. Was the tool successful? Did it produce the information needed to answer \\nthe user\\'s query? Or did it return an error that requires a different approach?\\nAs you can see, orchestration happens through this powerful feedback loop, often called \\nthe\\xa0Thought-Action-Observation\\xa0cycle. The agent observes the outcome of its action \\nand uses that new information to fuel its next \"thought,\" deciding whether the task is \\ncomplete, if it needs to use another tool, or if it should ask the user for clarification.\\nThis Thought-Action-Observation cycle forms the fundamental reasoning loop in modern agentic \\nframeworks like Elysia.\\nThe Next Frontier of Tool Use\\nThe evolution of tool use is moving more and more towards standardization. While \\nfunction/tool calling works well, it creates a fragmented ecosystem where each AI \\napplication needs custom integrations with every external system. The Model Context \\nProtocol (MCP), introduced by Anthropic in late 2024, addresses this by providing a \\nuniversal standard for connecting AI applications to external data sources and tools. \\nThey call it \"USB-C for AI\" - a single protocol that any MCP-compatible AI application can \\nuse to connect to any MCP server.\\nSo, instead of building custom integrations for each tool, developers can just create \\nindividual MCP servers that expose their systems through this standardized interface. \\nAny AI application that supports MCP can then easily connect to these servers using the \\nJSON-RPC based protocol for client-server communication. This transforms the MxN \\nintegration problem (where M applications each need custom code for N tools) into a \\nmuch simpler M + N problem.\\nThis shift towards composable, standardized architectures, where frameworks enable \\ndevelopers to build agents from modular, interoperable components, represents the \\nfuture of AI tooling. It changes the engineer\\'s role from writing custom integrations to \\norchestrating adaptive systems that can easily connect to any standardized external \\nsystem.\\nTraditional Integration vs MCP Approach\\nModel 1\\nDatabase\\nGit\\nCloud Storage\\nModel 3\\nModel 2\\nTraditional: NxM Connections\\nEach model needs custom integration \\nwith each data source\\n9 Total Connections\\nVisual inspired by : https://humanloop.com/blog/mcp\\nMCP: N+M Connections\\nModels and data sources only need \\nto integrate once with MCP\\n6 Total Connections\\nDatabase\\nGit\\nCloud Storage\\nMCP\\nModel 1\\nModel 3\\nModel 2\\n38\\n39\\nContext engineering'),\n",
       " Document(metadata={'producer': '', 'creator': '', 'creationdate': '2025-10-29T17:50:14+01:00', 'source': '../data/pdf_files/Context Engineering.pdf', 'file_path': '../data/pdf_files/Context Engineering.pdf', 'total_pages': 23, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-11-03T13:21:51+01:00', 'trapped': '', 'modDate': \"D:20251103132151+01'00'\", 'creationDate': \"D:20251029175014+01'00'\", 'page': 22}, page_content=\"Summary\\nContext engineering is about more than just prompting large language models, building \\nretrieval systems, or designing AI architectures. It’s about building interconnected, \\ndynamic systems that reliably work across a variety of uses and users. All the \\ncomponents described in this ebook will continue to evolve as new techniques, models, \\nand discoveries are made, but the difference between truly functional systems and the AI \\napps that fail will be how well they engineer context across their entire architecture. We \\nare no longer thinking in terms of just prompting a model, we’re looking at how we \\narchitect entire context systems.\\nVisual inspired by Effective context engineering for AI agents, Anthropic\\nSystem Prompt\\nSystem Prompt\\nUser Message\\nMessage History\\nUser Message\\nMessage History\\nAssistant\\nMessage\\nAssistant\\nMessage\\nDoc\\nTool\\nTool\\nTool\\nMemory File\\nMemory File\\nMemory File\\nTool\\nTool\\nTool\\nTool\\nTool Call\\nTool Result\\nDoc\\nDoc\\nDoc\\nDoc\\nDoc\\nCuration\\nPossible context to give model\\nSimple Prompt Engineering\\nContext Engineering\\nContext window\\nContext window\\nDomain Knowledge\\nComprehensive \\nInstructions\\nContext engineering is made up of the components described in this ebook:\\nAgents\\xa0to act as the system's decision-making brain.\\nQuery Augmentation\\xa0to translate messy human requests into actionable intent.\\nRetrieval\\xa0to connect the model to facts and knowledge bases.\\nMemory\\xa0to give your system a sense of history and the power to learn.\\nTools\\xa0to give your application hands to interact with live data and APIs.\\nWe are moving on from being prompters who talk\\xa0to\\xa0a model and instead, becoming \\narchitects who build the world the model lives\\xa0in. We - the builders, the engineers, and \\nthe creators - know the truth: the best AI systems aren’t born from bigger models, but \\nfrom better engineering.\\nWe can’t wait to see what you build \\nReady to build the next \\ngeneration of AI applications?\\nStart today with a 14 day free trial \\nof\\xa0Weaviate Cloud (WCD).\\nContact Us\\nTry Now\\nUser\\nAI Agent\\nLLM\\nWeaviate Vector \\nDatatbase\\nGlossary\\nMemory\\nTools\\n40\\n41\\nContext engineering\"),\n",
       " Document(metadata={'producer': 'iLovePDF', 'creator': '', 'creationdate': '', 'source': '../data/pdf_files/SQL.pdf', 'file_path': '../data/pdf_files/SQL.pdf', 'total_pages': 1, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-10-11T07:36:48+00:00', 'trapped': '', 'modDate': 'D:20251011073648Z', 'creationDate': '', 'page': 0}, page_content='')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "\n",
    "## load all the pdf files from the directory\n",
    "\n",
    "dir_loader=DirectoryLoader(\n",
    "    \"../data/pdf_files\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=False\n",
    "\n",
    ")\n",
    "\n",
    "pdf_documents=dir_loader.load()\n",
    "pdf_documents\n",
    "\n",
    "### returns a list of documents present in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbdb4c",
   "metadata": {},
   "source": [
    "Embeddings & VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d9a6ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# import uuid\n",
    "# from typing import List,Dict,Any,Tuple\n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2224ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
